{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install numpy pandas matplotlib scikit-learn pmdarima prophet xgboost tensorflow optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dy_rl3MwrNY3",
        "outputId": "b8876823-067e-4155-f401-8ef08a42f7a4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pmdarima in /usr/local/lib/python3.11/dist-packages (2.0.4)\n",
            "Requirement already satisfied: prophet in /usr/local/lib/python3.11/dist-packages (1.1.7)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (2.1.4)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (4.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: Cython!=0.29.18,!=0.29.31,>=0.29 in /usr/local/lib/python3.11/dist-packages (from pmdarima) (3.0.12)\n",
            "Requirement already satisfied: statsmodels>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from pmdarima) (0.14.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.11/dist-packages (from pmdarima) (2.4.0)\n",
            "Requirement already satisfied: setuptools!=50.0.0,>=38.6.0 in /usr/local/lib/python3.11/dist-packages (from pmdarima) (75.2.0)\n",
            "Requirement already satisfied: cmdstanpy>=1.0.4 in /usr/local/lib/python3.11/dist-packages (from prophet) (1.2.5)\n",
            "Requirement already satisfied: holidays<1,>=0.25 in /usr/local/lib/python3.11/dist-packages (from prophet) (0.74)\n",
            "Requirement already satisfied: tqdm>=4.36.1 in /usr/local/lib/python3.11/dist-packages (from prophet) (4.67.1)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.11/dist-packages (from prophet) (6.5.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.21.5)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.14.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.73.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (1.16.2)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna) (6.9.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.41)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: stanio<2.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from cmdstanpy>=1.0.4->prophet) (0.5.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.6.15)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.3)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels>=0.13.2->pmdarima) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from prophet import Prophet\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dropout, Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import optuna\n",
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "u3zh84ruruBs"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "\n",
        "DATA_PATH = '/content/drive/MyDrive/projek/dataset/dataInflasi/inflation_clean_20250622_183819.csv'\n",
        "assert os.path.exists(DATA_PATH), \"File CSV tidak ditemukan!\""
      ],
      "metadata": {
        "id": "eIA-qPZarUKQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff6ecc07-65ad-4dbb-eca3-c041610c7344"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(DATA_PATH, parse_dates=['date'], index_col='date').sort_index()\n",
        "df = df.rename(columns={'inflation':'y'})"
      ],
      "metadata": {
        "id": "4I-R11kdrY3_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for lag in [1,3,6]:\n",
        "    df[f'lag_{lag}'] = df['y'].shift(lag)\n",
        "for win in [3,6]:\n",
        "    df[f'roll_{win}'] = df['y'].shift(1).rolling(win).mean()\n",
        "df_ml = df.dropna().copy()"
      ],
      "metadata": {
        "id": "GZDMJ3HPrcdA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_hold = 6\n",
        "train_ml, test_ml = df_ml.iloc[:-n_hold], df_ml.iloc[-n_hold:]\n",
        "y_train, y_test = train_ml['y'], test_ml['y']\n",
        "X_train, X_test = train_ml.drop(columns='y'), test_ml.drop(columns='y')"
      ],
      "metadata": {
        "id": "oPJDyWzMrntu"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def metrics(y_true, y_pred):\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    return mae, rmse"
      ],
      "metadata": {
        "id": "3DVWYtiYrqDn"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rf_objective(trial):\n",
        "    params = {'n_estimators': trial.suggest_int('n_estimators', 50, 300), 'max_depth': trial.suggest_int('max_depth', 3, 15), 'min_samples_split': trial.suggest_int('min_samples_split', 2, 10), 'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 5), 'random_state': 42}\n",
        "    model = RandomForestRegressor(**params)\n",
        "    model.fit(X_train, y_train)\n",
        "    preds = model.predict(X_train)\n",
        "    return mean_absolute_error(y_train, preds)\n",
        "\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(rf_objective, n_trials=30)\n",
        "best_rf_params = study.best_params\n",
        "print(\"Best RF params:\", best_rf_params)\n",
        "\n",
        "rf = RandomForestRegressor(**best_rf_params, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "pred_rf = rf.predict(X_test)\n",
        "mae_rf, rmse_rf = metrics(y_test, pred_rf)\n",
        "print(\"RF to MAE:\", mae_rf, \"RMSE:\", rmse_rf)"
      ],
      "metadata": {
        "id": "cSBlYfZAr6DH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62c5faa0-e49e-4bf5-f195-69d17271bd70"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-22 17:58:47,681] A new study created in memory with name: no-name-835083e4-9f4d-4886-ad1a-109af1f28dc8\n",
            "[I 2025-06-22 17:58:47,928] Trial 0 finished with value: 0.5028194279487137 and parameters: {'n_estimators': 110, 'max_depth': 3, 'min_samples_split': 3, 'min_samples_leaf': 5}. Best is trial 0 with value: 0.5028194279487137.\n",
            "[I 2025-06-22 17:58:48,042] Trial 1 finished with value: 0.3554826857411624 and parameters: {'n_estimators': 59, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 1 with value: 0.3554826857411624.\n",
            "[I 2025-06-22 17:58:48,430] Trial 2 finished with value: 0.31097018575534624 and parameters: {'n_estimators': 168, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 2 with value: 0.31097018575534624.\n",
            "[I 2025-06-22 17:58:49,013] Trial 3 finished with value: 0.37316157736677313 and parameters: {'n_estimators': 258, 'max_depth': 12, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 2 with value: 0.31097018575534624.\n",
            "[I 2025-06-22 17:58:49,264] Trial 4 finished with value: 0.3879922389897824 and parameters: {'n_estimators': 64, 'max_depth': 12, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 2 with value: 0.31097018575534624.\n",
            "[I 2025-06-22 17:58:50,251] Trial 5 finished with value: 0.4014059804436526 and parameters: {'n_estimators': 248, 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 2 with value: 0.31097018575534624.\n",
            "[I 2025-06-22 17:58:50,472] Trial 6 finished with value: 0.33865796053408503 and parameters: {'n_estimators': 86, 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 2 with value: 0.31097018575534624.\n",
            "[I 2025-06-22 17:58:50,792] Trial 7 finished with value: 0.2196878190964809 and parameters: {'n_estimators': 69, 'max_depth': 15, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 7 with value: 0.2196878190964809.\n",
            "[I 2025-06-22 17:58:51,142] Trial 8 finished with value: 0.36183356188551385 and parameters: {'n_estimators': 56, 'max_depth': 14, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 7 with value: 0.2196878190964809.\n",
            "[I 2025-06-22 17:58:51,898] Trial 9 finished with value: 0.3176858078421611 and parameters: {'n_estimators': 161, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 7 with value: 0.2196878190964809.\n",
            "[I 2025-06-22 17:58:52,295] Trial 10 finished with value: 0.2524494167039878 and parameters: {'n_estimators': 138, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 7 with value: 0.2196878190964809.\n",
            "[I 2025-06-22 17:58:52,653] Trial 11 finished with value: 0.25382426115228435 and parameters: {'n_estimators': 125, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 7 with value: 0.2196878190964809.\n",
            "[I 2025-06-22 17:58:53,261] Trial 12 finished with value: 0.2697186612565225 and parameters: {'n_estimators': 207, 'max_depth': 13, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 7 with value: 0.2196878190964809.\n",
            "[I 2025-06-22 17:58:53,702] Trial 13 finished with value: 0.27192703900337 and parameters: {'n_estimators': 128, 'max_depth': 15, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 7 with value: 0.2196878190964809.\n",
            "[I 2025-06-22 17:58:54,352] Trial 14 finished with value: 0.26270465911924007 and parameters: {'n_estimators': 203, 'max_depth': 11, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 7 with value: 0.2196878190964809.\n",
            "[I 2025-06-22 17:58:54,705] Trial 15 finished with value: 0.31293158106966235 and parameters: {'n_estimators': 98, 'max_depth': 13, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 7 with value: 0.2196878190964809.\n",
            "[I 2025-06-22 17:58:55,555] Trial 16 finished with value: 0.2360638795468016 and parameters: {'n_estimators': 296, 'max_depth': 15, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 7 with value: 0.2196878190964809.\n",
            "[I 2025-06-22 17:58:56,252] Trial 17 finished with value: 0.3613284586644075 and parameters: {'n_estimators': 290, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 7 with value: 0.2196878190964809.\n",
            "[I 2025-06-22 17:58:56,891] Trial 18 finished with value: 0.260886309743536 and parameters: {'n_estimators': 210, 'max_depth': 15, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 7 with value: 0.2196878190964809.\n",
            "[I 2025-06-22 17:58:57,750] Trial 19 finished with value: 0.2938505820631552 and parameters: {'n_estimators': 287, 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 7 with value: 0.2196878190964809.\n",
            "[I 2025-06-22 17:58:58,343] Trial 20 finished with value: 0.3099527853854383 and parameters: {'n_estimators': 245, 'max_depth': 13, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 7 with value: 0.2196878190964809.\n",
            "[I 2025-06-22 17:58:58,758] Trial 21 finished with value: 0.2529140052683957 and parameters: {'n_estimators': 145, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 7 with value: 0.2196878190964809.\n",
            "[I 2025-06-22 17:58:59,614] Trial 22 finished with value: 0.25192386896514807 and parameters: {'n_estimators': 185, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 7 with value: 0.2196878190964809.\n",
            "[I 2025-06-22 17:59:00,566] Trial 23 finished with value: 0.28466112786282644 and parameters: {'n_estimators': 268, 'max_depth': 15, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 7 with value: 0.2196878190964809.\n",
            "[I 2025-06-22 17:59:01,263] Trial 24 finished with value: 0.23668873728429152 and parameters: {'n_estimators': 224, 'max_depth': 12, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 7 with value: 0.2196878190964809.\n",
            "[I 2025-06-22 17:59:02,074] Trial 25 finished with value: 0.26077621522193967 and parameters: {'n_estimators': 237, 'max_depth': 12, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 7 with value: 0.2196878190964809.\n",
            "[I 2025-06-22 17:59:03,561] Trial 26 finished with value: 0.20571555445669806 and parameters: {'n_estimators': 229, 'max_depth': 11, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 26 with value: 0.20571555445669806.\n",
            "[I 2025-06-22 17:59:04,778] Trial 27 finished with value: 0.3601687326098613 and parameters: {'n_estimators': 300, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 26 with value: 0.20571555445669806.\n",
            "[I 2025-06-22 17:59:05,584] Trial 28 finished with value: 0.2619145693212206 and parameters: {'n_estimators': 273, 'max_depth': 11, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 26 with value: 0.20571555445669806.\n",
            "[I 2025-06-22 17:59:06,027] Trial 29 finished with value: 0.4759830470816663 and parameters: {'n_estimators': 182, 'max_depth': 3, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 26 with value: 0.20571555445669806.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best RF params: {'n_estimators': 229, 'max_depth': 11, 'min_samples_split': 2, 'min_samples_leaf': 1}\n",
            "RF to MAE: 0.6123586851043191 RMSE: 0.7853047316981917\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ARIMA (univariate)\n",
        "model_arima = ARIMA(y_train, order=(1,1,1)).fit()\n",
        "pred_arima = model_arima.forecast(steps=n_hold)\n",
        "mae_arima, rmse_arima = metrics(y_test, pred_arima)\n",
        "print(\"ARIMA to MAE:\", mae_arima, \"RMSE:\", rmse_arima)"
      ],
      "metadata": {
        "id": "TM7GVWHkr6-G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9527942e-647d-4895-ff37-a71a94bde81f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ARIMA to MAE: 0.5713552773486761 RMSE: 0.7757616633724\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n",
            "  self._init_dates(dates, freq)\n",
            "/usr/local/lib/python3.11/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n",
            "  self._init_dates(dates, freq)\n",
            "/usr/local/lib/python3.11/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n",
            "  self._init_dates(dates, freq)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Facebook Prophet\n",
        "regs = ['lag_1','lag_3','lag_6','roll_3','roll_6']\n",
        "df_prop = df_ml.reset_index().rename(columns={'date':'ds','y':'y'})\n",
        "prop_train = df_prop.iloc[:-n_hold]\n",
        "m = Prophet(yearly_seasonality=True, weekly_seasonality=False, daily_seasonality=False)\n",
        "for col in regs:\n",
        "    m.add_regressor(col)\n",
        "m.fit(prop_train)\n",
        "\n",
        "future = m.make_future_dataframe(periods=n_hold, freq='M')\n",
        "future = future.merge(df_prop[['ds']+regs], on='ds', how='left')\n",
        "last_vals = df_prop[regs].iloc[-1]\n",
        "for col in regs:\n",
        "    future[col].fillna(last_vals[col], inplace=True)\n",
        "\n",
        "fcst = m.predict(future)\n",
        "pred_prop = fcst.set_index('ds')['yhat'].iloc[-n_hold:]\n",
        "mae_prop, rmse_prop = metrics(y_test, pred_prop)\n",
        "print(\"Prophet to MAE:\", mae_prop, \"RMSE:\", rmse_prop)\n"
      ],
      "metadata": {
        "id": "OeOkyWyLr-EY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c79e2c3f-cf7e-486b-abc3-2433b12f1619"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc4cxftco/goe9sgpj.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpc4cxftco/zpjne_3f.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.11/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=58050', 'data', 'file=/tmp/tmpc4cxftco/goe9sgpj.json', 'init=/tmp/tmpc4cxftco/zpjne_3f.json', 'output', 'file=/tmp/tmpc4cxftco/prophet_modelsjxtros0/prophet_model-20250622175906.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "17:59:06 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "17:59:06 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prophet to MAE: 0.796903164126029 RMSE: 1.0599748139152356\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/prophet/forecaster.py:1872: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
            "  dates = pd.date_range(\n",
            "/tmp/ipython-input-10-586929901.py:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  future[col].fillna(last_vals[col], inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#XGBoostRegressor\n",
        "xgb = XGBRegressor(n_estimators=200, max_depth=4, learning_rate=0.1, random_state=42)\n",
        "xgb.fit(X_train, y_train)\n",
        "pred_xgb = xgb.predict(X_test)\n",
        "mae_xgb, rmse_xgb = metrics(y_test, pred_xgb)\n",
        "print(\"XGBoost to MAE:\", mae_xgb, \"RMSE:\", rmse_xgb)"
      ],
      "metadata": {
        "id": "udLe7v6bsNVC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6c49325-0ac0-43dc-8846-8fc7ecb89ef4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost to MAE: 0.612481013139089 RMSE: 0.7854452425191203\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Linear Regression\n",
        "lr = LinearRegression()\n",
        "lr.fit(X_train, y_train)\n",
        "pred_lr = lr.predict(X_test)\n",
        "mae_lr, rmse_lr = metrics(y_test, pred_lr)\n",
        "print(\"LinReg to MAE:\", mae_lr, \"RMSE:\", rmse_lr)"
      ],
      "metadata": {
        "id": "SNoInF_JsPUZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c333b623-6ec0-4acb-e2a8-b686deedb5a8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LinReg to MAE: 0.6614442245000506 RMSE: 0.7337662383129492\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#LSTM Neural Network\n",
        "series = df['y'].values.reshape(-1,1)\n",
        "scaler = MinMaxScaler()\n",
        "scaled = scaler.fit_transform(series)\n",
        "\n",
        "def create_dataset(ds, time_step=12):\n",
        "    X, y = [], []\n",
        "    for i in range(len(ds)-time_step):\n",
        "        X.append(ds[i:i+time_step,0])\n",
        "        y.append(ds[i+time_step,0])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "time_step = 12\n",
        "X_l, y_l = create_dataset(scaled, time_step)\n",
        "X_l = X_l.reshape(X_l.shape[0], X_l.shape[1], 1)\n",
        "train_size = int(len(X_l)*0.8)\n",
        "Xl_train, Xl_test = X_l[:train_size], X_l[train_size:]\n",
        "yl_train, yl_test = y_l[:train_size], y_l[train_size:]\n",
        "\n",
        "model_lstm = Sequential([LSTM(64, return_sequences=True, input_shape=(time_step,1)), Dropout(0.2), LSTM(32), Dropout(0.2), Dense(1)])\n",
        "model_lstm.compile(optimizer='adam', loss='mse')\n",
        "es = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "history = model_lstm.fit(Xl_train, yl_train, validation_data=(Xl_test, yl_test),epochs=100, batch_size=16, callbacks=[es], verbose=1)\n",
        "\n",
        "yl_pred = model_lstm.predict(Xl_test)\n",
        "yl_pred_inv = scaler.inverse_transform(yl_pred)\n",
        "yl_test_inv = scaler.inverse_transform(yl_test.reshape(-1,1))\n",
        "mae_lstm, rmse_lstm = metrics(yl_test_inv.flatten(), yl_pred_inv.flatten())\n",
        "print(\"LSTM to MAE:\", mae_lstm, \"RMSE:\", rmse_lstm)"
      ],
      "metadata": {
        "id": "g0j2NOdpsQ2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3398633-4723-40fd-fc1d-fc6de8795d10"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - loss: 0.0642 - val_loss: 0.0138\n",
            "Epoch 2/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0219 - val_loss: 0.0046\n",
            "Epoch 3/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0224 - val_loss: 0.0090\n",
            "Epoch 4/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0212 - val_loss: 0.0053\n",
            "Epoch 5/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0199 - val_loss: 0.0056\n",
            "Epoch 6/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0173 - val_loss: 0.0051\n",
            "Epoch 7/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0163 - val_loss: 0.0045\n",
            "Epoch 8/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0127 - val_loss: 0.0051\n",
            "Epoch 9/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0204 - val_loss: 0.0057\n",
            "Epoch 10/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0185 - val_loss: 0.0052\n",
            "Epoch 11/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0114 - val_loss: 0.0060\n",
            "Epoch 12/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0164 - val_loss: 0.0040\n",
            "Epoch 13/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0103 - val_loss: 0.0037\n",
            "Epoch 14/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0084 - val_loss: 0.0022\n",
            "Epoch 15/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0123 - val_loss: 0.0027\n",
            "Epoch 16/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0101 - val_loss: 0.0045\n",
            "Epoch 17/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0073 - val_loss: 0.0053\n",
            "Epoch 18/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0113 - val_loss: 0.0028\n",
            "Epoch 19/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0107 - val_loss: 0.0022\n",
            "Epoch 20/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0130 - val_loss: 0.0020\n",
            "Epoch 21/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0087 - val_loss: 0.0023\n",
            "Epoch 22/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0086 - val_loss: 0.0046\n",
            "Epoch 23/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0140 - val_loss: 0.0031\n",
            "Epoch 24/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0088 - val_loss: 0.0023\n",
            "Epoch 25/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0084 - val_loss: 0.0024\n",
            "Epoch 26/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0088 - val_loss: 0.0026\n",
            "Epoch 27/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0105 - val_loss: 0.0020\n",
            "Epoch 28/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0103 - val_loss: 0.0022\n",
            "Epoch 29/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0083 - val_loss: 0.0017\n",
            "Epoch 30/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0090 - val_loss: 0.0035\n",
            "Epoch 31/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0070 - val_loss: 0.0020\n",
            "Epoch 32/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0115 - val_loss: 0.0016\n",
            "Epoch 33/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0079 - val_loss: 0.0023\n",
            "Epoch 34/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0055 - val_loss: 0.0023\n",
            "Epoch 35/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0097 - val_loss: 0.0015\n",
            "Epoch 36/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0058 - val_loss: 0.0034\n",
            "Epoch 37/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0094 - val_loss: 0.0016\n",
            "Epoch 38/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0100 - val_loss: 0.0021\n",
            "Epoch 39/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0069 - val_loss: 0.0026\n",
            "Epoch 40/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0090 - val_loss: 0.0015\n",
            "Epoch 41/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0102 - val_loss: 0.0019\n",
            "Epoch 42/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0070 - val_loss: 0.0016\n",
            "Epoch 43/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0114 - val_loss: 0.0016\n",
            "Epoch 44/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0065 - val_loss: 0.0029\n",
            "Epoch 45/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0089 - val_loss: 0.0015\n",
            "Epoch 46/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0108 - val_loss: 0.0016\n",
            "Epoch 47/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0060 - val_loss: 0.0019\n",
            "Epoch 48/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0075 - val_loss: 0.0016\n",
            "Epoch 49/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0054 - val_loss: 0.0018\n",
            "Epoch 50/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0100 - val_loss: 0.0014\n",
            "Epoch 51/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0055 - val_loss: 0.0017\n",
            "Epoch 52/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0065 - val_loss: 0.0015\n",
            "Epoch 53/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0074 - val_loss: 0.0022\n",
            "Epoch 54/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 0.0081 - val_loss: 0.0015\n",
            "Epoch 55/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0070 - val_loss: 0.0018\n",
            "Epoch 56/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0080 - val_loss: 0.0014\n",
            "Epoch 57/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0054 - val_loss: 0.0016\n",
            "Epoch 58/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0062 - val_loss: 0.0014\n",
            "Epoch 59/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0053 - val_loss: 0.0018\n",
            "Epoch 60/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0069 - val_loss: 0.0015\n",
            "Epoch 61/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0049 - val_loss: 0.0020\n",
            "Epoch 62/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0072 - val_loss: 0.0017\n",
            "Epoch 63/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0084 - val_loss: 0.0017\n",
            "Epoch 64/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0072 - val_loss: 0.0014\n",
            "Epoch 65/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0066 - val_loss: 0.0012\n",
            "Epoch 66/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0078 - val_loss: 0.0013\n",
            "Epoch 67/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0092 - val_loss: 0.0012\n",
            "Epoch 68/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0048 - val_loss: 0.0016\n",
            "Epoch 69/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0061 - val_loss: 0.0014\n",
            "Epoch 70/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0083 - val_loss: 0.0012\n",
            "Epoch 71/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0050 - val_loss: 0.0015\n",
            "Epoch 72/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0054 - val_loss: 0.0013\n",
            "Epoch 73/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0075 - val_loss: 0.0015\n",
            "Epoch 74/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0073 - val_loss: 0.0016\n",
            "Epoch 75/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0053 - val_loss: 0.0017\n",
            "Epoch 76/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0057 - val_loss: 0.0012\n",
            "Epoch 77/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0045 - val_loss: 0.0015\n",
            "Epoch 78/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0057 - val_loss: 0.0011\n",
            "Epoch 79/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0049 - val_loss: 0.0014\n",
            "Epoch 80/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0054 - val_loss: 0.0012\n",
            "Epoch 81/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0061 - val_loss: 0.0014\n",
            "Epoch 82/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0066 - val_loss: 0.0014\n",
            "Epoch 83/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0056 - val_loss: 0.0013\n",
            "Epoch 84/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0054 - val_loss: 0.0011\n",
            "Epoch 85/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0074 - val_loss: 0.0011\n",
            "Epoch 86/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0034 - val_loss: 0.0011\n",
            "Epoch 87/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0050 - val_loss: 0.0013\n",
            "Epoch 88/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0055 - val_loss: 0.0011\n",
            "Epoch 89/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0055 - val_loss: 0.0015\n",
            "Epoch 90/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0042 - val_loss: 0.0012\n",
            "Epoch 91/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0062 - val_loss: 0.0012\n",
            "Epoch 92/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0040 - val_loss: 0.0011\n",
            "Epoch 93/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0059 - val_loss: 0.0014\n",
            "Epoch 94/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0046 - val_loss: 0.0010\n",
            "Epoch 95/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0063 - val_loss: 0.0011\n",
            "Epoch 96/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0058 - val_loss: 9.6736e-04\n",
            "Epoch 97/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0065 - val_loss: 0.0020\n",
            "Epoch 98/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0076 - val_loss: 9.7443e-04\n",
            "Epoch 99/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0042 - val_loss: 0.0013\n",
            "Epoch 100/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0067 - val_loss: 0.0014\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step\n",
            "LSTM to MAE: 0.4357594008629139 RMSE: 0.5744623798167192\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = pd.DataFrame({'model': ['ARIMA','Prophet','RandomForest','XGBoost','LinearReg','LSTM'], 'MAE': [mae_arima, mae_prop, mae_rf, mae_xgb, mae_lr, mae_lstm], 'RMSE': [rmse_arima, rmse_prop, rmse_rf, rmse_xgb, rmse_lr, rmse_lstm]})\n",
        "results = results.sort_values(by='MAE').reset_index(drop=True)\n",
        "print(results)"
      ],
      "metadata": {
        "id": "svhV8IWesU0K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3e258ce-c6bb-40b8-9219-9289d80a8f14"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          model       MAE      RMSE\n",
            "0          LSTM  0.435759  0.574462\n",
            "1         ARIMA  0.571355  0.775762\n",
            "2  RandomForest  0.612359  0.785305\n",
            "3       XGBoost  0.612481  0.785445\n",
            "4     LinearReg  0.661444  0.733766\n",
            "5       Prophet  0.796903  1.059975\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "horizon = 5\n",
        "last_date = df.index[-1]\n",
        "future_dates = [last_date + pd.DateOffset(months=i) for i in range(1, horizon+1)]\n",
        "\n",
        "preds_arima = model_arima.predict(n_periods=horizon)\n",
        "\n",
        "fut = m.make_future_dataframe(periods=horizon, freq='M')\n",
        "fut = fut.merge(df_prop[['ds'] + regs], on='ds', how='left')\n",
        "for col in regs:\n",
        "    fut[col] = fut[col].fillna(last_vals[col])\n",
        "\n",
        "fc2 = m.predict(fut)\n",
        "preds_prop = fc2['yhat'].iloc[-horizon:].values\n",
        "\n",
        "history = df['y'].tolist()\n",
        "preds_rf, preds_xgb, preds_lr = [], [], []\n",
        "for _ in range(horizon):\n",
        "    feat = {'lag_1': history[-1], 'lag_3': history[-3], 'lag_6': history[-6], 'roll_3': pd.Series(history).shift(1).rolling(3).mean().iloc[-1], 'roll_6': pd.Series(history).shift(1).rolling(6).mean().iloc[-1]}\n",
        "    Xn = pd.DataFrame([feat])\n",
        "    p_rf  = rf.predict(Xn)[0]\n",
        "    p_xgb = xgb.predict(Xn)[0]\n",
        "    p_lr  = lr.predict(Xn)[0]\n",
        "    preds_rf.append(p_rf); preds_xgb.append(p_xgb); preds_lr.append(p_lr)\n",
        "    history.append(p_rf)\n",
        "\n",
        "X_future = scaled[-time_step:].reshape(1, time_step, 1)\n",
        "preds_lstm = []\n",
        "for _ in range(horizon):\n",
        "    p = model_lstm.predict(X_future)[0,0]\n",
        "    preds_lstm.append(p)\n",
        "    X_future = np.roll(X_future, -1)\n",
        "    X_future[0, -1, 0] = p\n",
        "preds_lstm = scaler.inverse_transform(np.array(preds_lstm).reshape(-1,1)).flatten()\n",
        "\n",
        "pred_df = pd.DataFrame({'Model': ['Prophet','ARIMA','RandomForest','XGBoost','LinearReg','LSTM']})\n",
        "for i, dt in enumerate(future_dates):\n",
        "    col = dt.strftime('%Y-%m')\n",
        "    pred_df[col] = [preds_prop[i], preds_arima[i], preds_rf[i], preds_xgb[i], preds_lr[i], preds_lstm[i]]\n",
        "# Format persen\n",
        "for col in pred_df.columns[1:]:\n",
        "    pred_df[col] = pred_df[col].map(lambda x: f\"{x:.2f}%\")\n",
        "\n",
        "print(pred_df)\n"
      ],
      "metadata": {
        "id": "cvOTeapGsYSx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5578d2e4-2282-46f2-fd1b-105d1750802e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/prophet/forecaster.py:1872: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
            "  dates = pd.date_range(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "          Model 2025-06 2025-07 2025-08 2025-09 2025-10\n",
            "0       Prophet   2.01%   2.06%   2.02%   1.49%   1.99%\n",
            "1         ARIMA   0.00%   6.98%   6.13%   6.62%   6.24%\n",
            "2  RandomForest   1.60%   1.58%   1.64%   1.61%   1.62%\n",
            "3       XGBoost   1.60%   1.65%   1.59%   1.59%   1.68%\n",
            "4     LinearReg   2.15%   2.13%   1.70%   1.93%   1.84%\n",
            "5          LSTM   1.33%   1.39%   1.41%   1.41%   1.40%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-15-3327460441.py:38: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  pred_df[col] = [preds_prop[i], preds_arima[i], preds_rf[i], preds_xgb[i], preds_lr[i], preds_lstm[i]]\n",
            "/tmp/ipython-input-15-3327460441.py:38: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  pred_df[col] = [preds_prop[i], preds_arima[i], preds_rf[i], preds_xgb[i], preds_lr[i], preds_lstm[i]]\n",
            "/tmp/ipython-input-15-3327460441.py:38: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  pred_df[col] = [preds_prop[i], preds_arima[i], preds_rf[i], preds_xgb[i], preds_lr[i], preds_lstm[i]]\n",
            "/tmp/ipython-input-15-3327460441.py:38: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  pred_df[col] = [preds_prop[i], preds_arima[i], preds_rf[i], preds_xgb[i], preds_lr[i], preds_lstm[i]]\n",
            "/tmp/ipython-input-15-3327460441.py:38: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  pred_df[col] = [preds_prop[i], preds_arima[i], preds_rf[i], preds_xgb[i], preds_lr[i], preds_lstm[i]]\n"
          ]
        }
      ]
    }
  ]
}